FROM apache/spark:3.5.0

USER root

# Install Python (needed if you run PySpark)
RUN apt-get update && apt-get install -y python3 python3-pip wget && \
    pip3 install --no-cache-dir pyspark==3.5.0 && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Create spark jars folder
RUN mkdir -p /opt/spark/jars

# -----------------------------
# Kafka dependencies
# -----------------------------
RUN wget -q https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar -P /opt/spark/jars/ && \
    wget -q https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.5.1/kafka-clients-3.5.1.jar -P /opt/spark/jars/ && \
    wget -q https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.0/spark-token-provider-kafka-0-10_2.12-3.5.0.jar -P /opt/spark/jars/ && \
    wget -q https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.12.0/commons-pool2-2.12.0.jar -P /opt/spark/jars/

# -----------------------------
# Hadoop AWS + AWS SDK v2
# -----------------------------
RUN wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.1/hadoop-aws-3.3.1.jar -P /opt/spark/jars/ && \
    wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.520/aws-java-sdk-bundle-1.12.520.jar -P /opt/spark/jars/


# Create spark user if not exists
RUN id -u spark >/dev/null 2>&1 || useradd -m -u 1000 spark
USER spark
WORKDIR /opt/spark
